#!/usr/bin/env python3
import os
import random

import numpy as np
import roslib
import rospy
import torch
import math
from cv_bridge import CvBridge, CvBridgeError
from mas_perception_msgs.msg import ImageList, Object, ObjectList, BoundingBox
from sensor_msgs.msg import Image, RegionOfInterest
from geometry_msgs.msg import Point
from rgb_object_recognition.yolov7.models.experimental import attempt_load
from rgb_object_recognition.yolov7.utils.datasets import letterbox
from rgb_object_recognition.yolov7.utils.general import check_img_size, non_max_suppression, apply_classifier, \
    scale_coords, xyxy2xywh
from rgb_object_recognition.yolov7.utils.plots import plot_one_box
from rgb_object_recognition.yolov7.utils.torch_utils import select_device, TracedModel, load_classifier, \
    time_synchronized
from ultralytics import YOLO


class RGBObjectRecognizer():
    def __init__(self, weights, 
                 net='detection', 
                 model_name='yolov8',
                 confidence_threshold=0.65,
                 iou_threshold=0.45,
                 img_size=640,
                 trace=True,
                 classify=False,
                 augment=False,
                 device='cpu',
                 debug_mode=True):

        self.cvbridge = CvBridge()
        self.debug = debug_mode
        self.pub_debug = rospy.Publisher(
            "/mir_perception/multimodal_object_recognition/recognizer/rgb/output/debug_image", Image, queue_size=1)
        self.pub_result = rospy.Publisher(
            "output/object_list", ObjectList, queue_size=1)
        self.sub_img = rospy.Subscriber(
            "input/images", ImageList, self.image_recognition_cb)
        self.net = net
        self.model_name = model_name
        self.weights = weights
        self.confidence_threshold = confidence_threshold
        self.iou_threshold = iou_threshold
        self.device = "cuda" if torch.cuda.is_available() else device

        # Load model
        if self.model_name == 'yolov8':
            self.model_atwork = YOLO(self.weights[0])
            self.model_cavity = YOLO(self.weights[1])

    def image_recognition_cb(self, img_msg):
        if img_msg.images:
            result_list = ObjectList()
            objects = []
            rospy.loginfo("[{}] images received: {} ".format(
                len(img_msg.images), self.model_name))
            if self.net == 'detection':
                try:
                    cv_img = self.cvbridge.imgmsg_to_cv2(
                        img_msg.images[0], "bgr8")
                    obj_category = None

                    if rospy.has_param("/mir_perception/multimodal_object_recognition/obj_category"):
                        obj_category = rospy.get_param("/mir_perception/multimodal_object_recognition/obj_category")
                        if obj_category == "cavity":
                            self.model = self.model_cavity
                        else:
                            self.model = self.model_atwork
                        # print the model name
                        rospy.loginfo(f"\033[92m" + f"[RGB Recognizer] is using {obj_category} objects category model" + f"\033[0m")
                    else:
                        rospy.loginfo(f"\033[92m" + f"[RGB Recognizer] is using atwork objects category model" + f"\033[0m")

                    if self.model_name == 'yolov8':
                        rospy.loginfo(f"\033[92m" + f"[RGB Recognizer] object category {obj_category}" + f"\033[0m")
                        predictions = self.model.predict(source=cv_img,
                                                         conf=self.confidence_threshold,
                                                         iou=self.iou_threshold,
                                                         device=self.device,
                                                         verbose=False
                                                        )
                        rospy.loginfo(f"\033[92m" + f"[RGB Recognizer] object category {obj_category}" + f"\033[0m")
                        if obj_category == "cavity":
                            # # Uncomment to run segmention model
                            # preds = predictions[0]
                            # class_ids = preds.boxes.cls
                            # class_labels = [self.model.names[int(label)] for label in class_ids.cpu().numpy()]
                            # class_scores = preds.boxes.conf.cpu().numpy()
                            # class_masks = preds.masks

                            # masks, probs, labels = class_masks, class_scores, class_labels

                            # for i in range(len(labels)):
                            #     result = Object()
                            #     result.name = labels[i].upper()
                            #     result.probability = probs[i]
                            #     result.mask = self.mask_to_sensor_msgs_image(masks[i].data[0].cpu().numpy())
                            #     objects.append(result)

                            # convert results to numpy array
                            predictions_np = predictions[0].boxes.numpy()
                            class_ids = predictions_np.cls
                            class_names = predictions[0].names
                            class_labels = [class_names[i] for i in class_ids]
                            class_scores = predictions_np.conf
                            class_bboxes = predictions_np.xyxy # x, y, w, h

                            bboxes, probs, labels = class_bboxes, class_scores, class_labels

                            for i in range(len(labels)):
                                result = Object()
                                result.name = labels[i].upper()
                                result.probability = probs[i]
                                roi = RegionOfInterest()
                                roi.x_offset = int(bboxes[i][0]) # is it center???
                                roi.y_offset = int(bboxes[i][1])
                                roi.width = int(bboxes[i][2] - bboxes[i][0])
                                roi.height = int(bboxes[i][3] - bboxes[i][1])
                                result.roi = roi

                                objects.append(result)
                        
                        else:
                            predictions_cp = predictions[0].obb.cpu()
                            class_ids = predictions_cp.cls.numpy()
                            class_labels = [self.model.names[int(label)] for label in class_ids]
                            class_scores = predictions_cp.conf.numpy()
                            class_bboxes = predictions_cp.xyxyxyxy.numpy()

                            bboxes, probs, labels = class_bboxes, class_scores, class_labels

                            for i in range(len(labels)):
                                if labels[i].upper() == "CONTAINER_BLUE":
                                    labels[i] = "CONTAINER_BOX_BLUE"
                                elif labels[i].upper() == "CONTAINER_RED":
                                    labels[i] = "CONTAINER_BOX_RED"

                                result = Object()
                                result.name = labels[i].upper()
                                result.probability = probs[i]
                                obbbox = BoundingBox()
                                for j, vertex in enumerate(bboxes[i]):
                                    point = Point()
                                    point.x = vertex[0]
                                    point.y = vertex[1]
                                    obbbox.vertices.append(point)
                                length, breadth = self.rectangle_dimensions(obbbox.vertices)
                                obbbox.dimensions.x = length
                                obbbox.dimensions.y = breadth
                                result.bounding_box = obbbox

                                objects.append(result)

                        if self.debug:

                            # Draw bounding boxes and labels of detections
                            debug_img = predictions[0].plot()

                            # publish bbox and label
                            self.publish_debug_img(debug_img)
                    
                    else:
                        rospy.logerr("[RGB Recognition] Model not supported")
                        return

                    # Publish result_list
                    result_list.objects = objects
                    self.pub_result.publish(result_list)

                except CvBridgeError as e:
                    rospy.logerr(e)
                    return

            elif self.net == 'classification':
                rospy.logwarn("TODO: MobileNet")

    def rectangle_dimensions(self, vertices):
        """Compute the length and breadth of a rectangle from its vertices."""
        # Assuming vertices are provided in the order: bottom1, bottom2, top2, top1

        # Extracting coordinates from geometry_msgs.Point
        bottom1_x, bottom1_y = vertices[0].x, vertices[0].y
        bottom2_x, bottom2_y = vertices[1].x, vertices[1].y
        top2_x, top2_y = vertices[2].x, vertices[2].y

        # Compute lengths along x and y axes
        length = math.sqrt((top2_x - bottom1_x) ** 2 + (top2_y - bottom1_y) ** 2)
        breadth = math.sqrt((bottom2_x - bottom1_x) ** 2 + (bottom2_y - bottom1_y) ** 2)

        return length, breadth

    def mask_to_sensor_msgs_image(self, mask):
        """
        Convert a binary mask (numpy array of 0s and 1s) to a ROS sensor_msgs/Image message.

        Parameters:
        mask (numpy.ndarray): The binary mask to be converted.

        Returns:
        sensor_msgs/Image: The populated ROS Image message with the mask data.
        """
        # Create a new Image message
        image_msg = Image()

        # Set the header (optional, but good practice)
        image_msg.header.stamp = rospy.Time.now()
        image_msg.header.frame_id = "mask_frame"

        # Set the image dimensions
        image_msg.height = mask.shape[0]  # Number of rows
        image_msg.width = mask.shape[1]   # Number of columns

        # Set the encoding to mono8 since it's a single-channel binary mask
        image_msg.encoding = "mono8"

        # Set dummy values for these fields, necessary for the message but not used
        image_msg.is_bigendian = 0
        image_msg.step = image_msg.width  # Full row length in bytes

        # Convert the mask to uint8 and flatten it to a list for the data field
        mask_uint8 = (mask * 255).astype(np.uint8)  # Convert 1s to 255s for visibility
        image_msg.data = mask_uint8.flatten().tolist()

        return image_msg

    def publish_debug_img(self, debug_img):
        debug_img = np.array(debug_img, dtype=np.uint8)
        debug_img = self.cvbridge.cv2_to_imgmsg(debug_img, "bgr8")
        self.pub_debug.publish(debug_img)


if __name__ == '__main__':
    rospy.init_node("rgb_object_recognizer")
    rospy.loginfo('Started object recognition node.')
    net = rospy.get_param("~net")
    classifier_name = rospy.get_param("~classifier")
    dataset = rospy.get_param("~dataset")
    model_dir = rospy.get_param("~model_dir")
    model_category = rospy.get_param("~model_category")
    # breakpoint()
    weight_1 = os.path.join(roslib.packages.get_pkg_dir("mir_rgb_object_recognition_models"),
                           'common', 'models', classifier_name, dataset, model_category[0]+".pt")
    weight_2 = os.path.join(roslib.packages.get_pkg_dir("mir_rgb_object_recognition_models"),
                            'common', 'models', classifier_name, dataset, model_category[1]+".pt")
    
    rospy.loginfo(f"\033[92m" + f"[RGB Recognizer] is using {weight_1} model" + f"\033[0m")
    # check if the model exists
    if not os.path.isfile(weight_1):
        rospy.logerr("[RGB Recognition] Model not found: %s", weight_1)
        exit(-1)
    if not os.path.isfile(weight_2):
        rospy.logerr("[RGB Recognition] Model not found: %s", weight_2)
        exit(-1)
    weights = [weight_1, weight_2] # 0th index is the default model, eg. atwork
    rospy.loginfo(f"\033[92m" + f"[RGB Recognizer] is using {weights} model" + f"\033[0m")
    object_recognizer = RGBObjectRecognizer(
        weights, 
        debug_mode=True)
    rospy.loginfo("\033[92m" + "RGB Recognizer is ready using %s : %s , dataset: %s " + "\033[0m",
              net, classifier_name, dataset)
    rospy.spin()
